---
layout: positions
title: Python Intern
category: Web
technologies: [ Python, Scrapy, Twitter Feeds, NLP, GCP, NoSQL, Data Analytics]
position_type: intern
project_title: Crawling 0.1 million RSS feeds and Analysing the Big Data
---

The project is about crawling 0.1 million RSS Feeds on regular basis
and save the data into a NoSQL database. We will run some analytics like
understanding the trends, sentiments and other minimal things.

The aim of project is to understand more about writing efficient code to handle the BigData
crawling, analytics, setting up and scaling the infrastructure for the process.


##### Requirements

- Solid understanding and coding experience with Python 3x (we don't teach you python)
- Should be good with concepts like Classes and Multiple Inheritance in python.
- Should have good understanding of Git and GitHub


##### What you get
- Quite a few components of this code are open-source, so you will experience
writing code in opensource(GitHub)
- Working experience in handling big data
- Working experience on Google Cloud Platform.
